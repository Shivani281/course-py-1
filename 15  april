{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03acea64-bb67-43bb-84bc-ea5dc48423a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1. Designing a Feature Engineering Pipeline:\n",
    "\n",
    "To automate the feature engineering process and handle missing values, you can create a pipeline with the following steps:\n",
    "\n",
    "Step 1: Automated Feature Selection:\n",
    "\n",
    "Use a feature selection method such as Recursive Feature Elimination (RFE) or SelectKBest to identify important features in the dataset.\n",
    "Step 2: Numerical Pipeline:\n",
    "\n",
    "Impute missing values in numerical columns using the mean of the column values.\n",
    "Scale the numerical columns using standardization.\n",
    "Step 3: Categorical Pipeline:\n",
    "\n",
    "Impute missing values in categorical columns using the most frequent value of the column.\n",
    "One-hot encode the categorical columns.\n",
    "Step 4: ColumnTransformer:\n",
    "\n",
    "Combine the outputs of the numerical and categorical pipelines using ColumnTransformer.\n",
    "Step 5: Random Forest Classifier:\n",
    "\n",
    "Build the final model using a Random Forest Classifier.\n",
    "Step 6: Evaluation:\n",
    "\n",
    "Evaluate the accuracy of the model on the test dataset.\n",
    "Here's a Python code snippet that demonstrates how to create this feature engineering pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Assuming 'X' is your feature matrix and 'y' is your target variable\n",
    "\n",
    "# Step 1: Automated Feature Selection\n",
    "feature_selection = SelectKBest(k=10)  # Select the top 10 features (adjust as needed)\n",
    "\n",
    "# Step 2: Numerical Pipeline\n",
    "numerical_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Step 3: Categorical Pipeline\n",
    "categorical_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OneHotEncoder())\n",
    "])\n",
    "\n",
    "# Step 4: ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_pipeline, numerical_features),  # Provide the list of numerical feature names\n",
    "        ('cat', categorical_pipeline, categorical_features)  # Provide the list of categorical feature names\n",
    "    ])\n",
    "\n",
    "# Step 5: Random Forest Classifier\n",
    "rf_classifier = RandomForestClassifier()\n",
    "\n",
    "# Step 6: Combine all steps in the main pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('feature_selection', feature_selection),\n",
    "    ('preprocessing', preprocessor),\n",
    "    ('classifier', rf_classifier)\n",
    "])\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Fit the pipeline on the training data\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Step 7: Evaluation\n",
    "y_pred = pipeline.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "# Interpretation and suggestions for improvements can be made based on the accuracy and model performance.\n",
    "Q2. Building a Pipeline with Voting Classifier:\n",
    "\n",
    "To build a pipeline that includes both a Random Forest Classifier and a Logistic Regression Classifier, and then combine their predictions using a Voting Classifier, you can follow these steps:\n",
    "\n",
    "python\n",
    "Copy code\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Assuming 'X' is your feature matrix and 'y' is your target variable\n",
    "\n",
    "# Step 1: Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Step 2: Create individual classifiers\n",
    "rf_classifier = RandomForestClassifier(random_state=42)\n",
    "logistic_classifier = LogisticRegression(random_state=42)\n",
    "\n",
    "# Step 3: Create a Voting Classifier\n",
    "voting_classifier = VotingClassifier(estimators=[\n",
    "    ('random_forest', rf_classifier),\n",
    "    ('logistic_regression', logistic_classifier)\n",
    "], voting='hard')  # 'hard' voting means majority class wins\n",
    "\n",
    "# Step 4: Fit the Voting Classifier on the training data\n",
    "voting_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Step 5: Evaluate the accuracy of the ensemble model on the test dataset\n",
    "y_pred = voting_classifier.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "# You now have an ensemble model that combines the predictions of a Random Forest Classifier and a Logistic Regression Classifier.\n",
    "This pipeline trains both classifiers separately and combines their predictions through majority voting. You can adjust the classifiers and voting method as needed for your specific problem."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
